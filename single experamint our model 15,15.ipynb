{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 168, 60)           660       \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 159, 60)           36060     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 79, 60)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 79, 60)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 70, 100)           60100     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 61, 100)           100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 30, 100)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 26, 50)            25050     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 222,225\n",
      "Trainable params: 222,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Number of columns in the dataframe: 177\n",
      "Number of rows in the dataframe: 11500\n",
      "\n",
      "\n",
      "--- Create neural network model ---\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 168, 60)           660       \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 159, 60)           36060     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 79, 60)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 79, 60)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 70, 100)           60100     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 61, 100)           100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 30, 100)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 26, 50)            25050     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 222,225\n",
      "Trainable params: 222,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "--- Reshape data to be accepted by Keras ---\n",
      "\n",
      "(9889, 177, 1)\n",
      "(9889, 5)\n",
      "\n",
      "--- Fit the model ---\n",
      "\n",
      "Train on 8405 samples, validate on 1484 samples\n",
      "Epoch 1/20\n",
      "8405/8405 [==============================] - 1s 168us/step - loss: 2.3067 - acc: 0.2054 - val_loss: 1.4651 - val_acc: 0.1853\n",
      "Epoch 2/20\n",
      "8405/8405 [==============================] - 1s 93us/step - loss: 1.4164 - acc: 0.2416 - val_loss: 1.4513 - val_acc: 0.3181\n",
      "Epoch 3/20\n",
      "8405/8405 [==============================] - 1s 89us/step - loss: 1.3648 - acc: 0.2864 - val_loss: 1.3854 - val_acc: 0.4407\n",
      "Epoch 4/20\n",
      "8405/8405 [==============================] - 1s 90us/step - loss: 1.2989 - acc: 0.3795 - val_loss: 1.2897 - val_acc: 0.5054\n",
      "Epoch 5/20\n",
      "8405/8405 [==============================] - 1s 93us/step - loss: 1.2384 - acc: 0.4564 - val_loss: 1.1448 - val_acc: 0.5478\n",
      "Epoch 6/20\n",
      "8405/8405 [==============================] - 1s 92us/step - loss: 1.1309 - acc: 0.5154 - val_loss: 1.0231 - val_acc: 0.5364\n",
      "Epoch 7/20\n",
      "8405/8405 [==============================] - 1s 93us/step - loss: 1.0248 - acc: 0.5441 - val_loss: 0.9544 - val_acc: 0.5788\n",
      "Epoch 8/20\n",
      "8405/8405 [==============================] - 1s 91us/step - loss: 0.9933 - acc: 0.5459 - val_loss: 0.8501 - val_acc: 0.6354\n",
      "Epoch 9/20\n",
      "8405/8405 [==============================] - 1s 90us/step - loss: 0.9061 - acc: 0.5851 - val_loss: 0.8319 - val_acc: 0.6105\n",
      "Epoch 10/20\n",
      "8405/8405 [==============================] - 1s 90us/step - loss: 0.8780 - acc: 0.6051 - val_loss: 0.8390 - val_acc: 0.5741\n",
      "Epoch 11/20\n",
      "8405/8405 [==============================] - 1s 91us/step - loss: 0.8542 - acc: 0.6063 - val_loss: 0.7970 - val_acc: 0.6294\n",
      "Epoch 12/20\n",
      "8405/8405 [==============================] - 1s 91us/step - loss: 0.8594 - acc: 0.5990 - val_loss: 0.8084 - val_acc: 0.5937\n",
      "Epoch 13/20\n",
      "8405/8405 [==============================] - 1s 91us/step - loss: 0.8079 - acc: 0.6207 - val_loss: 0.7327 - val_acc: 0.6422\n",
      "Epoch 14/20\n",
      "8405/8405 [==============================] - 1s 91us/step - loss: 0.8291 - acc: 0.6180 - val_loss: 0.9559 - val_acc: 0.5189\n",
      "Epoch 15/20\n",
      "8405/8405 [==============================] - 1s 92us/step - loss: 0.8162 - acc: 0.6234 - val_loss: 0.7636 - val_acc: 0.6085\n",
      "Epoch 16/20\n",
      "8405/8405 [==============================] - 1s 91us/step - loss: 0.8025 - acc: 0.6318 - val_loss: 0.8273 - val_acc: 0.5600\n",
      "Epoch 17/20\n",
      "8405/8405 [==============================] - 1s 92us/step - loss: 0.7808 - acc: 0.6295 - val_loss: 0.7463 - val_acc: 0.6408\n",
      "Epoch 18/20\n",
      "8405/8405 [==============================] - 1s 92us/step - loss: 0.8007 - acc: 0.6383 - val_loss: 0.7863 - val_acc: 0.6199\n",
      "Epoch 19/20\n",
      "8405/8405 [==============================] - 1s 92us/step - loss: 0.7539 - acc: 0.6514 - val_loss: 0.7632 - val_acc: 0.6280\n",
      "Epoch 20/20\n",
      "8405/8405 [==============================] - 1s 90us/step - loss: 0.7348 - acc: 0.6547 - val_loss: 0.9235 - val_acc: 0.5532\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'History' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-20cbcd7d95e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;31m#callbacks=callbacks_list,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                     validation_split=0.15, verbose=1)\n\u001b[0;32m--> 197\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Avarage accuracy :\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2920\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'History' and 'int'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "import scipy as sp\n",
    "import scipy.io as spio\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline\n",
    "from tensorflow.python import keras\n",
    "from sklearn.model_selection import train_test_split ,KFold\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv1D, Dropout, MaxPooling1D, Reshape, GlobalAveragePooling1D\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras.layers import LeakyReLU\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import keras.backend as k\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "\n",
    "dataset = np.loadtxt(\"datalast.csv\",delimiter=\",\")\n",
    "\n",
    "def feature_normalize(dataset):\n",
    "\n",
    "    mu = np.mean(dataset, axis=0)\n",
    "    sigma = np.std(dataset, axis=0)\n",
    "    z=(dataset - mu)/sigma\n",
    "    dataset=stats.zscore(z)\n",
    "    return (dataset)\n",
    "\n",
    "feature_normalize(dataset)\n",
    "\n",
    "X = dataset[:,0:177]\n",
    "y = dataset[:,178]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.14, random_state=0)\n",
    "\n",
    "\n",
    "LABELS = [\"0\",\n",
    "\n",
    "          \"1\",\n",
    "\n",
    "          \"2\",\n",
    "\n",
    "          \"3\",\n",
    "\n",
    "          \"4\"]\n",
    "\n",
    " \n",
    "\n",
    "def show_confusion_matrix(validations, predictions):\n",
    " \n",
    "\n",
    "    #matrix = metrics.confusion_matrix(y_test_hot, predictions)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    sns.heatmap(c,\n",
    "\n",
    "                cmap=\"coolwarm\",\n",
    "\n",
    "                linecolor='white',\n",
    "\n",
    "                linewidths=1,\n",
    "\n",
    "                xticklabels=LABELS,\n",
    "\n",
    "                yticklabels=LABELS,\n",
    "\n",
    "                annot=True,\n",
    "\n",
    "                fmt=\"d\")\n",
    "\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "\n",
    "    plt.ylabel(\"True Label\")\n",
    "\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def counts_from_confusion(confusion):\n",
    "\n",
    "    counts_list=[]\n",
    "    \n",
    "# Iterate through classes and store the counts\n",
    "\n",
    "    for i in range(confusion.shape[0]):\n",
    "\n",
    "        tp = confusion[i, i]\n",
    "        \n",
    "        fn_mask = np.zeros(confusion.shape)\n",
    "\n",
    "        fn_mask[i, :] = 1\n",
    "\n",
    "        fn_mask[i, i] = 0\n",
    "\n",
    "        fn = np.sum(np.multiply(confusion, fn_mask))\n",
    "\n",
    "\n",
    "\n",
    "        fp_mask = np.zeros(confusion.shape)\n",
    "\n",
    "        fp_mask[:, i] = 1\n",
    "\n",
    "        fp_mask[i, i] = 0\n",
    "\n",
    "        fp = np.sum(np.multiply(confusion, fp_mask))\n",
    "        \n",
    "        tn_mask = 1 - (fn_mask + fp_mask)\n",
    "\n",
    "        tn_mask[i, i] = 0\n",
    "\n",
    "        tn = np.sum(np.multiply(confusion, tn_mask))\n",
    "\n",
    "\n",
    "\n",
    "        counts_list.append({'Class': i,\n",
    "\n",
    "                           'TP': tp,\n",
    "   \n",
    "                           'FN': fn,\n",
    "\n",
    "                           'FP': fp,\n",
    "\n",
    "                           'TN': tn})\n",
    "         \n",
    "        print('sensitivity', tp / tp + fn)\n",
    "\n",
    "        print('specificity', tn / tn + fp)\n",
    "\n",
    "    return counts_list\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(60, 10, activation='relu', input_shape=(177,1)))\n",
    "model.add(Conv1D(60, 10, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(100, 10, activation='relu'))\n",
    "model.add(Conv1D(100, 10, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(50, 5, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "print(\"Number of columns in the dataframe: %i\" % (X.shape[1]))\n",
    "print(\"Number of rows in the dataframe: %i\\n\" % (X.shape[0]))\n",
    "print(\"\\n--- Create neural network model ---\\n\")\n",
    "print(model.summary())\n",
    "cvscores = []\n",
    "j=1\n",
    "\n",
    "#kf=KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "scores = list()\n",
    "# summarize scores\n",
    "#def summarize_results(scores):\n",
    "  #  m, s = mean(scores), std(scores)\n",
    " #   print('Accuracy: %.3f%%(+/-%.3f)' % (m ,s) )\n",
    "\n",
    "   \n",
    "print(\"\\n--- Reshape data to be accepted by Keras ---\\n\")\n",
    "X_train = np.reshape(X_train,(X_train.shape[0], X_train.shape[1],1))\n",
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "y_train_hot = np_utils.to_categorical(y_train-1, 5) # subtracting y_train-1 as keras starts num_Classes index from 0 and we had it from 1 to 5\n",
    "print(X_train.shape)\n",
    "print(y_train_hot.shape)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "print(\"\\n--- Fit the model ---\\n\")\n",
    "history = model.fit(X_train, y_train_hot, batch_size = 400, epochs=20,\n",
    "                    #callbacks=callbacks_list,\n",
    "                    validation_split=0.15, verbose=1)\n",
    "#print(\"Avarage accuracy :\" , np.mean(history))\n",
    "\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "y_train_hot = np.argmax(y_train_hot, axis=-1)\n",
    "\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "c = confusion_matrix(y_train_hot, predictions)\n",
    "\n",
    "print('Confusion matrix:\\n', c)\n",
    "print(counts_from_confusion(c))\n",
    "show_confusion_matrix(y_train_hot, predictions)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "y_test_hot = np_utils.to_categorical(y_test-1, 5)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"\\n--- evaluate the model ---\\n\")\n",
    "scores = model.evaluate(X_test, y_test_hot,verbose=1)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "y_test_hot = np.argmax(y_test_hot, axis=-1)\n",
    "\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "c = confusion_matrix(y_test_hot, predictions)\n",
    "\n",
    "print('Confusion matrix:\\n', c)\n",
    "print(counts_from_confusion(c))\n",
    "show_confusion_matrix(y_test_hot, predictions)\n",
    "\n",
    "print(\"\\n--- Learning curve of model training ---\\n\")\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'], \"g--\", label=\"Accuracy of training data\")\n",
    "plt.plot(history.history['val_acc'], \"g\", label=\"Accuracy of validation data\")\n",
    "plt.plot(history.history['loss'], \"r--\", label=\"Loss of training data\")\n",
    "plt.plot(history.history['val_loss'], \"r\", label=\"Loss of validation data\")\n",
    "\n",
    "plt.title('Model Accuracy and Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "cvscores.append(scores[1] * 100)\n",
    "print(\"Avarage accuracy :%.2f% %\" , np.mean(cvscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
